name: EPG-MX

on:
  workflow_dispatch:
  schedule:
    - cron: "0 7 * * *" # daily 07:00 UTC

concurrency:
  group: epg-mx
  cancel-in-progress: true

jobs:
  mx:
    runs-on: ubuntu-latest
    timeout-minutes: 300
    env:
      MX_SEARCH_URL: https://iptv-org.github.io/?q=live%20country:MX
      MX_EPG_URL: https://epgshare01.online/epgshare01/epg_ripper_MX1.xml.gz
      HEADLESS: "true"
      MAX_CHANNELS: "0"         # set to e.g. 25 for test runs
      PER_PAGE_DELAY_MS: "150"
      NAV_TIMEOUT_MS: "30000"
      PROBE_TIMEOUT_MS: "5000"
      SUPABASE_TABLE: mx_channels
      SUPABASE_SCHEMA: public
      # Provide these via repo secrets:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}

    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Install Playwright and deps
        run: |
          npm i --no-save playwright fast-xml-parser @supabase/supabase-js
          npx playwright install --with-deps chromium

      - name: Write script
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p scripts out/mx
          cat > scripts/mx-scrape-and-match.mjs <<'EOF'
          import { chromium } from 'playwright';
          import { XMLParser } from 'fast-xml-parser';
          import zlib from 'node:zlib';
          import fs from 'node:fs/promises';
          import path from 'node:path';
          import { setTimeout as delay } from 'node:timers/promises';
          import { createClient } from '@supabase/supabase-js';

          const SEARCH_URL = process.env.MX_SEARCH_URL || 'https://iptv-org.github.io/?q=live%20country:MX';
          const EPG_GZ_URL = process.env.MX_EPG_URL || 'https://epgshare01.online/epgshare01/epg_ripper_MX1.xml.gz';

          const HEADLESS = (process.env.HEADLESS ?? 'true') !== 'false';
          const MAX_CHANNELS = Number(process.env.MAX_CHANNELS || '0'); // 0 = no cap
          const PER_PAGE_DELAY_MS = Number(process.env.PER_PAGE_DELAY_MS || '150');
          const NAV_TIMEOUT_MS = Number(process.env.NAV_TIMEOUT_MS || '30000');
          const PROBE_TIMEOUT_MS = Number(process.env.PROBE_TIMEOUT_MS || '5000');

          const SUPABASE_URL = process.env.SUPABASE_URL || '';
          const SUPABASE_SERVICE_KEY = process.env.SUPABASE_SERVICE_KEY || '';
          const SUPABASE_TABLE = process.env.SUPABASE_TABLE || 'mx_channels';
          const SUPABASE_SCHEMA = process.env.SUPABASE_SCHEMA || 'public';

          function stripAccents(s) { return String(s).normalize('NFD').replace(/\p{Diacritic}+/gu, ''); }
          const STOP = new Set(['canal', 'tv', 'television', 'hd', 'sd', 'mx', 'mexico', 'méxico']);
          function tokensOf(s) {
            if (!s) return [];
            const plain = stripAccents(String(s).toLowerCase());
            const cleaned = plain.replace(/&/g, ' and ').replace(/[^a-z0-9]+/g, ' ').trim();
            return cleaned.split(/\s+/).filter(t => t && !STOP.has(t));
          }
          function keyOf(s) {
            const t = Array.from(new Set(tokensOf(s))).sort();
            return t.join(' ');
          }

          // --- Name variant helpers for matching ("Canal." removal, dot/underscore flatten)
          function stripLeadingCanal(s) {
            if (!s) return s;
            return String(s).replace(/^\s*canal[\s._-]+/i, '');
          }
          function expandNameVariants(s) {
            if (!s) return [];
            const out = new Set();
            const orig = String(s).trim();
            const noCanal = stripLeadingCanal(orig);
            out.add(orig);
            out.add(noCanal);
            out.add(orig.replace(/[._]+/g, ' ').replace(/\s+/g, ' ').trim());
            out.add(noCanal.replace(/[._]+/g, ' ').replace(/\s+/g, ' ').trim());
            return [...out].filter(Boolean);
          }

          function uniqBy(arr, keyFn) {
            const m = new Map();
            for (const x of arr) {
              const k = keyFn(x);
              if (!m.has(k)) m.set(k, x);
            }
            return [...m.values()];
          }

          async function fetchBuf(url) {
            const r = await fetch(url);
            if (!r.ok) throw new Error(`Fetch failed ${r.status} ${url}`);
            return Buffer.from(await r.arrayBuffer());
          }

          // ---------- SCRAPE CHANNEL LIST PAGE ----------
          async function collectChannelPages(browser) {
            const page = await browser.newPage();
            page.setDefaultTimeout(NAV_TIMEOUT_MS);
            await page.goto(SEARCH_URL, { waitUntil: 'domcontentloaded' });
            await page.waitForSelector('a[href*="/channels/"]', { timeout: 15000 }).catch(() => {});
            await page.waitForTimeout(1000);

            let items = await page.$$eval('a[href*="/channels/"]', (as) => {
              const out = [];
              for (const a of as) {
                const href = a.getAttribute('href') || '';
                if (!href.includes('/channels/')) continue;
                const url = new URL(href, location.href).href;
                const name = (a.textContent || '').trim();
                let logo = null;
                const row = a.closest('tr,li,article,div') || a.parentElement;
                if (row) {
                  const img = row.querySelector('img');
                  if (img) logo = img.src || img.getAttribute('src');
                }
                out.push({ url, name, logo });
              }
              const m = new Map();
              for (const it of out) if (!m.has(it.url)) m.set(it.url, it);
              return [...m.values()];
            });

            items = items.filter(i => i.name && i.url);
            items = uniqBy(items, x => x.url);

            if (MAX_CHANNELS > 0 && items.length > MAX_CHANNELS) items = items.slice(0, MAX_CHANNELS);
            await page.close();
            return items.map(i => ({ ...i, nameKey: keyOf(i.name) }));
          }

          // ---------- SCRAPE PER-CHANNEL PAGE FOR .m3u8 ----------
          async function scrapeChannel(browser, link) {
            const page = await browser.newPage();
            page.setDefaultTimeout(NAV_TIMEOUT_MS);
            try {
              await page.goto(link.url, { waitUntil: 'domcontentloaded' });
              await page.waitForTimeout(500);

              const tab = await page.$('text=Streams');
              if (tab) {
                await tab.click().catch(() => {});
                await page.waitForTimeout(400);
              }

              let anchors = await page.$$eval('a[href*=".m3u8"]', els =>
                els.map(e => ({ url: e.href, text: (e.textContent || '').trim() }))
              );

              if (!anchors.length) {
                const html = await page.content();
                const rx = /https?:\/\/[^\s"'<>]+\.m3u8[^\s"'<>]*/gi;
                const set = new Set();
                let m;
                while ((m = rx.exec(html))) set.add(m[0]);
                anchors = [...set].map(u => ({ url: u, text: '' }));
              }

              anchors = uniqBy(anchors.filter(a => /^https?:\/\//i.test(a.url)), a => a.url);

              return anchors.map(a => ({
                url: a.url,
                quality: (a.text.match(/\b(1080p|720p|480p|360p|HD|SD)\b/i) || [])[0] || null
              }));
            } catch (e) {
              console.error(`Error scraping ${link.url}: ${e.message}`);
              return [];
            } finally {
              await page.close();
            }
          }

          async function scrapeAll(browser, links) {
            const out = [];
            for (const lnk of links) {
              const streams = await scrapeChannel(browser, lnk);
              if (streams.length) {
                out.push({
                  channelName: lnk.name,
                  channelNameKey: lnk.nameKey,
                  channelPage: lnk.url,
                  logo: lnk.logo || null,
                  streams
                });
              }
              await delay(PER_PAGE_DELAY_MS);
            }
            return out;
          }

          // ---------- PROBE M3U8 QUICKLY ----------
          async function probeM3U8(url) {
            const ac = new AbortController();
            const t = setTimeout(() => ac.abort(), PROBE_TIMEOUT_MS);
            try {
              const r = await fetch(url, {
                method: 'GET',
                headers: { 'user-agent': 'Mozilla/5.0', 'accept': 'application/vnd.apple.mpegurl,text/plain,*/*' },
                signal: ac.signal
              });
              if (!r.ok) return false;
              const txt = await r.text();
              return txt.includes('#EXTM3U');
            } catch {
              return false;
            } finally {
              clearTimeout(t);
            }
          }

          // ---------- PARSE EPG SHARE & BUILD NAME INDEX ----------
          async function parseEpgMx() {
            console.log(`Downloading EPGShare MX… ${EPG_GZ_URL}`);
            const gz = await fetchBuf(EPG_GZ_URL);
            const xmlBuf = zlib.gunzipSync(gz);
            const xml = xmlBuf.toString('utf8');

            const parser = new XMLParser({
              ignoreAttributes: false,
              attributeNamePrefix: '',
              trimValues: true
            });
            const doc = parser.parse(xml);

            const channels = doc?.tv?.channel
              ? (Array.isArray(doc.tv.channel) ? doc.tv.channel : [doc.tv.channel])
              : [];

            const programmes = doc?.tv?.programme
              ? (Array.isArray(doc.tv.programme) ? doc.tv.programme : [doc.tv.programme])
              : [];

            const idTo = new Map();
            const nameMap = new Map();

            for (const ch of channels) {
              const id = ch?.id;
              if (!id) continue;

              let icon = null;
              if (ch.icon) {
                if (Array.isArray(ch.icon)) {
                  for (const ic of ch.icon) { if (ic?.src) { icon = ic.src; break; } }
                } else if (typeof ch.icon === 'object' && ch.icon.src) {
                  icon = ch.icon.src;
                }
              }

              const names = [];
              const dn = ch['display-name'];
              const pushVariants = (v) => { for (const x of expandNameVariants(v)) names.push(x); };
              if (Array.isArray(dn)) dn.forEach(v => pushVariants(typeof v === 'object' ? (v['#text'] || v.text || '') : v));
              else pushVariants(typeof dn === 'object' ? (dn?.['#text'] || dn?.text || '') : dn);

              for (const x of expandNameVariants(id)) names.push(x);

              const entry = { id, names: Array.from(new Set(names.filter(Boolean))), icon, hasProgs: false };
              idTo.set(id, entry);
              for (const n of entry.names) {
                const k = keyOf(n);
                if (!k) continue;
                if (!nameMap.has(k)) nameMap.set(k, entry);
              }
            }

            for (const p of programmes) {
              const cid = p?.channel;
              const o = idTo.get(cid);
              if (o) o.hasProgs = true;
            }

            for (const [k, v] of nameMap.entries()) if (!v.hasProgs) nameMap.delete(k);

            console.log(`EPG channels: ${channels.length}, with programmes for ${[...new Set([...idTo.values()].filter(x=>x.hasProgs).map(x=>x.id))].length}`);
            return { nameMap };
          }

          // ---------- MATCH ----------
          function match(scraped, nameMap) {
            const res = [];
            for (const s of scraped) {
              const hit = nameMap.get(s.channelNameKey);
              if (!hit) continue;
              res.push({
                channelName: s.channelName,
                channelPage: s.channelPage,
                logo: s.logo,
                streams: s.streams,
                epgChannelId: hit.id,
                epgDisplayNames: hit.names,
                epgIcon: hit.icon
              });
            }
            return res;
          }

          // ---------- SUPABASE UPSERT ----------
          async function upsertSupabase(rows) {
            if (!SUPABASE_URL || !SUPABASE_SERVICE_KEY) {
              console.log('Supabase env missing or no rows; skipped DB upload.');
              return;
            }
            if (!rows.length) {
              console.log('No rows to upload to Supabase.');
              return;
            }
            const supabase = createClient(SUPABASE_URL, SUPABASE_SERVICE_KEY, {
              auth: { persistSession: false },
              db: { schema: SUPABASE_SCHEMA }
            });
            const payload = [];
            for (const r of rows) {
              for (const s of r.streams) {
                payload.push({
                  country: 'MX',
                  channel_name: r.channelName,
                  channel_logo: r.logo,
                  channel_page: r.channelPage,
                  stream_url: s.url,
                  stream_quality: s.quality,
                  epg_channel_id: r.epgChannelId,
                  epg_display_names: r.epgDisplayNames,
                  epg_icon: r.epgIcon
                });
              }
            }
            const { error } = await supabase.from(SUPABASE_TABLE).upsert(payload, {
              onConflict: 'country,channel_name,stream_url',
              ignoreDuplicates: false
            });
            if (error) {
              console.warn(`Supabase upsert skipped: ${error.message} (${error.code ?? 'no-code'})`);
            } else {
              console.log(`Supabase upsert done: ${payload.length} rows`);
            }
          }

          // ---------- MAIN ----------
          async function ensureDir(p) { await fs.mkdir(p, { recursive: true }); }

          async function main() {
            await ensureDir('out/mx');
            const browser = await chromium.launch({ headless: HEADLESS });
            try {
              console.log(`Scraping: ${SEARCH_URL}`);
              const links = await collectChannelPages(browser);
              console.log(`Found ${links.length} channel pages.`);
              const scraped = await scrapeAll(browser, links);
              console.log(`Channels with at least one .m3u8 (before probe): ${scraped.length}`);

              for (const row of scraped) {
                const tested = [];
                for (const s of row.streams) {
                  const ok = await probeM3U8(s.url);
                  if (ok) tested.push(s);
                }
                row.streams = tested;
              }
              const filtered = scraped.filter(r => r.streams.length > 0);
              console.log(`Channels with at least one WORKING .m3u8: ${filtered.length}`);

              const { nameMap } = await parseEpgMx();
              const matched = match(filtered, nameMap);
              console.log(`Matched ${matched.length} channels with working streams & EPG.`);

              const outPath = path.join('out', 'mx', 'matches.json');
              await fs.writeFile(outPath, JSON.stringify(matched, null, 2), 'utf8');
              console.log(`Wrote ${outPath}`);

              await upsertSupabase(matched);
            } finally {
              await browser.close();
            }
          }

          main().catch((e) => {
            console.error(e);
            process.exit(1);
          });
          EOF

      - name: Run MX scrape & match
        run: node scripts/mx-scrape-and-match.mjs

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: mx-matches
          path: out/mx/matches.json
          if-no-files-found: error

name: EPG-MX

on:
  workflow_dispatch: {}
  schedule:
    - cron: '0 7 * * *' # daily 07:00 UTC

concurrency:
  group: epg-mx
  cancel-in-progress: true

jobs:
  mx:
    runs-on: ubuntu-latest
    timeout-minutes: 300

    env:
      MX_SEARCH_URL: https://iptv-org.github.io/?q=live%20country:MX
      MX_EPG_URLS: >-
        https://epgshare01.online/epgshare01/epg_ripper_US1.xml.gz
        https://epgshare01.online/epgshare01/epg_ripper_US_LOCALS2.xml.gz
        https://epgshare01.online/epgshare01/epg_ripper_MX1.xml.gz
      # Recommended: M3U containing tvg-id mappings
      M3U_URL: ${{ secrets.M3U_URL }}

      HEADLESS: 'true'
      MAX_CHANNELS: '0'
      PER_PAGE_DELAY_MS: '150'
      NAV_TIMEOUT_MS: '30000'
      PROBE_TIMEOUT_MS: '5000'
      FUZZY_MIN: '0.45'
      LOG_UNMATCHED: '1'

      # Program ingestion controls
      INGEST_PROGRAMS: '1'
      PROGRAMS_HOURS_AHEAD: '36'

      # Supabase
      SUPABASE_SCHEMA: public
      SUPABASE_TABLE: mx_channels
      PROGRAMS_TABLE: epg_programs
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}

      # Optional NordVPN (Mexico)
      NORDVPN_TOKEN: ${{ secrets.NORDVPN_TOKEN }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install Node deps (Playwright, Supabase, Saxes)
        run: |
          set -euo pipefail
          npm i --no-save playwright saxes @supabase/supabase-js
          npx playwright install --with-deps chromium

      - name: Install NordVPN CLI (non-interactive)
        if: ${{ env.NORDVPN_TOKEN != '' }}
        run: |
          set -euo pipefail
          sudo apt-get update
          sudo apt-get install -y curl gnupg expect
          curl -sSf https://repo.nordvpn.com/gpg/nordvpn_public.asc \
            | sudo gpg --dearmor -o /usr/share/keyrings/nordvpn-archive-keyring.gpg
          echo "deb [signed-by=/usr/share/keyrings/nordvpn-archive-keyring.gpg] https://repo.nordvpn.com/deb/nordvpn/debian stable main" \
            | sudo tee /etc/apt/sources.list.d/nordvpn.list
          sudo apt-get update
          sudo apt-get install -y nordvpn
          sudo systemctl enable --now nordvpnd || true

      - name: Write non-interactive nordvpn wrapper
        if: ${{ env.NORDVPN_TOKEN != '' }}
        run: |
          set -euo pipefail
          mkdir -p scripts
          cat > scripts/nordvpn.exp <<'EXP'
          #!/usr/bin/expect -f
          set timeout 120
          if {$argc < 1} { exit 2 }
          spawn sudo nordvpn {*}$argv
          expect {
            -re "(?i)Do you allow.*\\(y/n\\)" { send -- "no\r"; exp_continue }
            -re "(?i)answer with yes/no"     { send -- "no\r"; exp_continue }
            eof
          }
          EXP
          chmod +x scripts/nordvpn.exp

      - name: NordVPN login & connect (Mexico)
        if: ${{ env.NORDVPN_TOKEN != '' }}
        env:
          NORDVPN_TOKEN: ${{ env.NORDVPN_TOKEN }}
        run: |
          set -euo pipefail
          scripts/nordvpn.exp login --token "$NORDVPN_TOKEN"
          scripts/nordvpn.exp set analytics off
          scripts/nordvpn.exp set technology nordlynx
          scripts/nordvpn.exp set firewall off
          scripts/nordvpn.exp set killswitch off
          scripts/nordvpn.exp connect Mexico
          for i in $(seq 1 30); do
            if scripts/nordvpn.exp status | grep -qi "Status: Connected"; then
              echo "NordVPN connected (Mexico)."
              break
            fi
            sleep 2
          done

      - name: Write scraper script
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p scripts out/mx
          cat > scripts/mx-scrape-and-match.mjs <<'EOF'
// Scrape iptv-org for MX live channels, pull .m3u8s, probe them.
// Parse multiple EPG XML.GZ streams safely (saxes + streaming gunzip).
// Prefer mapping via M3U tvg-id (exact URL, then normalized name).
// Fallback to normalized-name matching vs EPG channels.
// Write artifacts and upsert streams into Supabase (mx_channels).
// Optionally ingest programmes into epg_programs (bounded window).

import { chromium } from 'playwright';
import { createGunzip } from 'node:zlib';
import { Readable } from 'node:stream';
import fs from 'node:fs/promises';
import path from 'node:path';
import { setTimeout as delay } from 'node:timers/promises';
import { createClient } from '@supabase/supabase-js';
import { SaxesParser } from 'saxes';

// ---------- ENV ----------
const SEARCH_URL = process.env.MX_SEARCH_URL || 'https://iptv-org.github.io/?q=live%20country:MX';
const EPG_URLS = (process.env.MX_EPG_URLS || '').trim().split(/\s+/).filter(Boolean);
const M3U_URL = (process.env.M3U_URL || '').trim();

const HEADLESS = (process.env.HEADLESS ?? 'true') !== 'false';
const MAX_CHANNELS = Number(process.env.MAX_CHANNELS || '0');
const PER_PAGE_DELAY_MS = Number(process.env.PER_PAGE_DELAY_MS || '150');
const NAV_TIMEOUT_MS = Number(process.env.NAV_TIMEOUT_MS || '30000');
const PROBE_TIMEOUT_MS = Number(process.env.PROBE_TIMEOUT_MS || '5000');

const FUZZY_MIN = Number(process.env.FUZZY_MIN || '0.45');
const LOG_UNMATCHED = process.env.LOG_UNMATCHED === '1';

const INGEST_PROGRAMS = (process.env.INGEST_PROGRAMS || '0') === '1';
const PROGRAMS_HOURS_AHEAD = Number(process.env.PROGRAMS_HOURS_AHEAD || '36');

const SUPABASE_URL = process.env.SUPABASE_URL || '';
const SUPABASE_SERVICE_KEY = process.env.SUPABASE_SERVICE_KEY || '';
const SUPABASE_SCHEMA = process.env.SUPABASE_SCHEMA || 'public';
const SUPABASE_TABLE = process.env.SUPABASE_TABLE || 'mx_channels';
const PROGRAMS_TABLE = process.env.PROGRAMS_TABLE || 'epg_programs';

// ---------- NORMALIZATION ----------
function stripAccents(s) { return String(s).normalize('NFD').replace(/\p{Diacritic}+/gu, ''); }
function normalizeNumerals(s) {
  const map = { uno:'1', dos:'2', tres:'3', cuatro:'4', cinco:'5', seis:'6', siete:'7', ocho:'8', nueve:'9', diez:'10', once:'11', doce:'12', trece:'13' };
  return String(s).replace(/\b(uno|dos|tres|cuatro|cinco|seis|siete|ocho|nueve|diez|once|doce|trece)\b/gi, m => map[m.toLowerCase()]);
}
function dropTimeshift(s) {
  return String(s)
    .replace(/(?:[-+]\s*\d+\s*(?:h|hora|horas)\b)/ig,'')
    .replace(/\b\d+\s*horas?\b/ig,'')
    .replace(/\(\s*\d+\s*horas?\s*\)/ig,'')
    .replace(/\btime\s*shift\b/ig,'')
    .replace(/\s{2,}/g,' ')
    .trim();
}
function stripLeadingCanal(s) { return String(s).replace(/^\s*canal[\s._-]+/i, ''); }
function stripCountryTail(s) { return String(s).replace(/(\.(mx|us)|\s+\(?mx\)?|\s+m[eé]xico|\s+usa|\s+eeuu)\s*$/i,'').trim(); }
const STOP = new Set(['canal','tv','television','hd','sd','mx','mexico','méxico','hora','horas','us','usa','eeuu']);
function tokensOf(s) {
  if (!s) return [];
  let p = stripAccents(normalizeNumerals(String(s).toLowerCase()));
  p = dropTimeshift(p);
  p = stripCountryTail(p);
  p = p.replace(/&/g, ' and ').replace(/[^a-z0-9]+/g, ' ').trim();
  return p.split(/\s+/).filter(t => t && !STOP.has(t));
}
function keyOf(s) { return Array.from(new Set(tokensOf(s))).sort().join(' '); }
function expandNameVariants(s) {
  if (!s) return [];
  const out = new Set();
  const orig = String(s).trim();
  const noCanal = stripLeadingCanal(orig);
  const flat = x => x.replace(/[._(),]+/g, ' ').replace(/\s+/g, ' ').trim();
  const noTS = dropTimeshift(noCanal);
  const noTail = stripCountryTail(noTS);
  [orig, noCanal, noTS, noTail, flat(orig), flat(noCanal), flat(noTS), flat(noTail)]
    .forEach(v => { if (v) out.add(v); });
  return [...out];
}
function containsMexicoTag(s) {
  const t = stripAccents(String(s).toLowerCase()).replace(/[^a-z0-9]+/g, ' ').trim();
  const parts = t.split(/\s+/);
  return parts.includes('mexico') || parts.includes('mx') || /\.mx\b/i.test(String(s));
}
function uniqBy(arr, keyFn) {
  const m = new Map();
  for (const x of arr) {
    const k = keyFn(x);
    if (!m.has(k)) m.set(k, x);
  }
  return [...m.values()];
}

// ---------- UTILS ----------
async function fetchText(u) {
  const r = await fetch(u);
  if (!r.ok) throw new Error(`Fetch failed ${r.status} ${u}`);
  return await r.text();
}
function parseXmltvToISO(s) {
  // XMLTV time like 20250827100000 +0000  or 20250827100000 -0500  or 20250827100000
  const m = String(s).match(/^(\d{4})(\d{2})(\d{2})(\d{2})(\d{2})(\d{2})(?:\s*([+-]\d{4}))?$/);
  if (!m) return null;
  const [, Y,Mo,D,h,mi,se, off] = m;
  const utcMs = Date.UTC(+Y, +Mo-1, +D, +h, +mi, +se);
  let delta = 0;
  if (off) {
    const sign = off.startsWith('-') ? -1 : 1;
    const hh = +off.slice(1,3), mm = +off.slice(3,5);
    delta = sign * (hh*60 + mm) * 60 * 1000;
  }
  const t = utcMs - delta; // convert to true UTC
  return new Date(t).toISOString();
}

// ---------- M3U PARSER ----------
function parseM3U(m3uText) {
  const items = [];
  let cur = null;
  for (const raw of m3uText.split(/\r?\n/)) {
    const line = raw.trim();
    if (!line) continue;
    if (line.startsWith('#EXTINF')) {
      const attrs = {};
      for (const m of line.matchAll(/\b([a-z0-9_-]+)="([^"]*)"/gi)) {
        attrs[m[1].toLowerCase()] = m[2];
      }
      const comma = line.indexOf(',');
      const title = comma >= 0 ? line.slice(comma + 1).trim() : '';
      cur = { tvg_id: attrs['tvg-id'] || null, tvg_name: attrs['tvg-name'] || title || null, url: null };
    } else if (!line.startsWith('#') && cur) {
      cur.url = line;
      items.push(cur);
      cur = null;
    }
  }
  return items;
}
async function buildM3ULookups() {
  const out = { byUrl: new Map(), byNameNorm: new Map() };
  if (!M3U_URL) return out;
  try {
    const txt = await fetchText(M3U_URL);
    const items = parseM3U(txt);
    for (const it of items) if (it.url && it.tvg_id) out.byUrl.set(it.url, it.tvg_id);
    const seen = new Set();
    for (const it of items) {
      if (!it.tvg_id) continue;
      const k = keyOf(it.tvg_name || '');
      if (k && !seen.has(k)) { out.byNameNorm.set(k, it.tvg_id); seen.add(k); }
    }
    console.log(`M3U parsed: ${items.length} entries, ${out.byUrl.size} url→tvg_id, ${out.byNameNorm.size} name→tvg_id.`);
  } catch (e) {
    console.warn(`M3U parse skipped: ${e.message}`);
  }
  return out;
}

// ---------- SCRAPING ----------
async function collectChannelPages(browser) {
  const page = await browser.newPage();
  page.setDefaultTimeout(NAV_TIMEOUT_MS);
  await page.goto(SEARCH_URL, { waitUntil: 'domcontentloaded' });
  await page.waitForSelector('a[href*="/channels/"]', { timeout: 15000 }).catch(() => {});
  await page.waitForTimeout(1000);

  let items = await page.$$eval('a[href*="/channels/"]', as => {
    const out = [];
    for (const a of as) {
      const href = a.getAttribute('href') || '';
      if (!href.includes('/channels/')) continue;
      const url = new URL(href, location.href).href;
      const name = (a.textContent || '').trim();
      out.push({ url, name });
    }
    const m = new Map();
    for (const it of out) if (!m.has(it.url)) m.set(it.url, it);
    return [...m.values()];
  });

  items = items.filter(i => i.name && i.url);
  items = uniqBy(items, x => x.url);
  if (MAX_CHANNELS > 0 && items.length > MAX_CHANNELS) items = items.slice(0, MAX_CHANNELS);
  await page.close();
  return items.map(i => ({ ...i, nameKey: keyOf(i.name) }));
}

async function scrapeChannel(browser, link) {
  const page = await browser.newPage();
  page.setDefaultTimeout(NAV_TIMEOUT_MS);
  try {
    await page.goto(link.url, { waitUntil: 'domcontentloaded' });
    await page.waitForTimeout(500);

    const tab = await page.$('text=Streams');
    if (tab) { await tab.click().catch(() => {}); await page.waitForTimeout(400); }

    let anchors = await page.$$eval('a[href*=".m3u8"]', els =>
      els.map(e => ({ url: e.href, text: (e.textContent || '').trim() }))
    );

    if (!anchors.length) {
      const html = await page.content();
      const rx = /https?:\/\/[^\s"'<>]+\.m3u8[^\s"'<>]*/gi;
      const set = new Set();
      let m; while ((m = rx.exec(html))) set.add(m[0]);
      anchors = [...set].map(u => ({ url: u, text: '' }));
    }

    anchors = uniqBy(anchors.filter(a => /^https?:\/\//i.test(a.url)), a => a.url);

    return anchors.map(a => ({
      url: a.url,
      quality: (a.text.match(/\b(1080p|720p|480p|360p|HD|SD)\b/i) || [])[0] || null
    }));
  } catch (e) {
    console.error(`Error scraping ${link.url}: ${e.message}`);
    return [];
  } finally {
    await page.close();
  }
}

async function scrapeAll(browser, links) {
  const out = [];
  for (const lnk of links) {
    const streams = await scrapeChannel(browser, lnk);
    if (streams.length) {
      out.push({
        channelName: lnk.name,
        channelNameKey: lnk.nameKey,
        streams
      });
    }
    await delay(PER_PAGE_DELAY_MS);
  }
  return out;
}

async function probeM3U8(url) {
  const ac = new AbortController();
  const t = setTimeout(() => ac.abort(), PROBE_TIMEOUT_MS);
  try {
    const r = await fetch(url, {
      method: 'GET',
      headers: { 'user-agent': 'Mozilla/5.0', 'accept': 'application/vnd.apple.mpegurl,text/plain,*/*' },
      signal: ac.signal
    });
    if (!r.ok) return false;
    const txt = await r.text();
    return txt.includes('#EXTM3U');
  } catch { return false; }
  finally { clearTimeout(t); }
}

// ---------- EPG PARSING ----------
function isMexicoEntry(id, names) {
  return /\.mx$/i.test(id || '') || (names || []).some(n => /\b(m[eé]xico|mx)\b/i.test(String(n)));
}

async function parseOneEpg(url, agg, keepAllMexFile) {
  console.log(`Downloading EPG (stream)… ${url}`);
  const res = await fetch(url);
  if (!res.ok || !res.body) throw new Error(`Fetch failed ${res.status} ${url}`);

  const gunzip = createGunzip();
  const src = Readable.fromWeb(res.body);
  const decoder = new TextDecoder('utf-8');
  const parser = new SaxesParser({ xmlns: false });

  const MAX_NAME_CHARS = 1024, MAX_NAMES_PER_CH = 24, MAX_VARIANTS = 64;

  let cur = null, inDisp = false, dispChunks = [], dispLen = 0, dispTruncated = false;

  parser.on('error', (e) => { throw e; });

  parser.on('opentag', (tag) => {
    const nm = String(tag.name).toLowerCase();
    if (nm === 'channel') {
      cur = { id: tag.attributes?.id ? String(tag.attributes.id) : '', namesRaw: [] };
    } else if (nm === 'display-name' && cur) {
      inDisp = true; dispChunks = []; dispLen = 0; dispTruncated = false;
    } else if (nm === 'programme') {
      const cid = String(tag.attributes?.channel || '');
      // Programme ingestion is handled on closetag when we have text nodes collected
      if (cid) agg.programmeOpen = { channel: cid, attrs: tag.attributes, text: {} };
      else agg.programmeOpen = null;
    }
  });

  parser.on('text', (t) => {
    if (inDisp && cur && t && !dispTruncated) {
      let chunk = String(t);
      if (chunk.length > MAX_NAME_CHARS) chunk = chunk.slice(0, MAX_NAME_CHARS);
      const remain = MAX_NAME_CHARS - dispLen;
      if (remain <= 0) { dispTruncated = true; return; }
      if (chunk.length > remain) { chunk = chunk.slice(0, remain); dispTruncated = true; }
      if (chunk) { dispChunks.push(chunk); dispLen += chunk.length; }
    } else if (agg.programmeOpen) {
      // collect simple text nodes by current tag (title, sub-title, desc, category, etc.)
      const curTag = parser.tag.name?.toLowerCase?.() || '';
      if (!curTag) return;
      const str = String(t).trim();
      if (!str) return;
      if (!agg.programmeOpen.text[curTag]) agg.programmeOpen.text[curTag] = [];
      agg.programmeOpen.text[curTag].push(str);
    }
  });

  parser.on('closetag', async (nameRaw) => {
    const nm = String(nameRaw).toLowerCase();
    if (nm === 'display-name' && cur) {
      if (cur.namesRaw.length < MAX_NAMES_PER_CH) {
        const txt = dispChunks.length ? dispChunks.join('') : '';
        const clean = txt.trim();
        if (clean) cur.namesRaw.push(clean);
      }
      inDisp = false; dispChunks = []; dispLen = 0; dispTruncated = false;
    } else if (nm === 'channel' && cur) {
      const id = cur.id || '';
      const keep = keepAllMexFile ? true : isMexicoEntry(id, cur.namesRaw);
      if (keep) {
        const names = new Set();
        for (const n of cur.namesRaw) for (const v of expandNameVariants(n)) if (v) names.add(v);
        for (const v of expandNameVariants(id)) if (v) names.add(v);
        const limited = [];
        for (const v of names) { limited.push(v); if (limited.length >= MAX_VARIANTS) break; }
        let entry = agg.channels.get(id);
        if (!entry) { entry = { id, names: [], tokenSet: new Set() }; agg.channels.set(id, entry); }
        entry.names = Array.from(new Set(entry.names.concat(limited))).slice(0, MAX_VARIANTS);
        entry.tokenSet = new Set();
        for (const nm2 of entry.names) for (const tok of tokensOf(nm2)) entry.tokenSet.add(tok);
        for (const n of entry.names) {
          const k = keyOf(n);
          if (k && !agg.nameMap.has(k)) agg.nameMap.set(k, entry);
        }
      }
      cur = null; inDisp = false; dispChunks = []; dispLen = 0; dispTruncated = false;
    } else if (nm === 'programme' && agg.programmeOpen) {
      if (!INGEST_PROGRAMS) { agg.programmeOpen = null; return; }

      const cid = agg.programmeOpen.channel;
      const entry = agg.channels.get(cid);
      const keep = keepAllMexFile ? true : (entry ? isMexicoEntry(entry.id, entry.names) : containsMexicoTag(cid));
      if (!keep) { agg.programmeOpen = null; return; }

      const attrs = agg.programmeOpen.attrs || {};
      const t = agg.programmeOpen.text || {};
      const now = Date.now();
      const ahead = now + PROGRAMS_HOURS_AHEAD * 3600 * 1000;

      const startISO = parseXmltvToISO(attrs.start || '');
      const stopISO  = parseXmltvToISO(attrs.stop  || '');

      if (!startISO || !stopISO) { agg.programmeOpen = null; return; }

      const startMs = Date.parse(startISO);
      const stopMs  = Date.parse(stopISO);
      if (Number.isFinite(startMs) && Number.isFinite(stopMs)) {
        if (stopMs < now - 6*3600*1000) { agg.programmeOpen = null; return; } // drop very old
        if (startMs > ahead) { agg.programmeOpen = null; return; } // too far ahead
      }

      const textOf = (k) => (t[k]?.join(' ') || null);
      const arrOf  = (k) => (t[k] ? Array.from(new Set(t[k])) : null);

      const rec = {
        channel_id: cid,
        title: textOf('title'),
        sub_title: textOf('sub-title'),
        summary: textOf('desc'),
        start_ts: startISO,
        stop_ts: stopISO,
        categories: arrOf('category'),
        icon_url: null,
        rating: t['rating'] ? { text: t['rating'].join(' ') } : null,
        star_rating: textOf('star-rating'),
        program_url: textOf('url'),
        episode_num_xmltv: textOf('episode-num'),
        season: null,
        episode: null,
        language: textOf('language'),
        orig_language: textOf('orig-language'),
        credits: null,
        premiere: !!t['premiere'],
        previously_shown: !!t['previously-shown'],
        extras: null,
        ingested_at: new Date().toISOString()
      };

      // Try to derive season/episode from xmltv_ns: "S.E.P/.."
      if (t['episode-num']) {
        const ns = t['episode-num'].find(x => /xmltv_ns/.test(x)) || null;
        const m = ns && ns.match(/(\d+)\.(\d+)(?:\.(\d+))?/);
        if (m) { rec.season = Number(m[1]) + 1; rec.episode = Number(m[2]) + 1; }
      }

      // Collect credits (actors, directors, etc.) if present
      const creditKeys = ['actor','director','writer','adapter','producer','composer','editor','presenter','commentator','guest'];
      const credits = {};
      for (const k of creditKeys) if (t[k]) credits[k] = Array.from(new Set(t[k]));
      rec.credits = Object.keys(credits).length ? credits : null;

      // Icon child tags are ignored in streaming text capture.

      agg.programmeBatch.push(rec);
      if (agg.programmeBatch.length >= 500) {
        await saveProgramsBatch(agg.programmeBatch);
        agg.programmeBatch = [];
      }

      agg.programmeOpen = null;
    }
  });

  await new Promise((resolve, reject) => {
    src.on('error', reject);
    gunzip.on('error', reject);
    gunzip.on('data', async (chunk) => {
      const text = decoder.decode(chunk, { stream: true });
      if (text) parser.write(text);
    });
    gunzip.on('end', async () => {
      parser.write(decoder.decode(new Uint8Array(), { stream: false }));
      parser.close();
      // flush any remaining programme batch
      if (INGEST_PROGRAMS && agg.programmeBatch.length) {
        await saveProgramsBatch(agg.programmeBatch);
        agg.programmeBatch = [];
      }
      resolve();
    });
    src.pipe(gunzip);
  });
}

async function parseAllEpg(urls) {
  const agg = {
    channels: new Map(),     // id -> { id, names[], tokenSet:Set }
    nameMap: new Map(),      // keyOf(name) -> entry
    programmeOpen: null,     // temp holder
    programmeBatch: []       // buffered programme rows
  };
  for (const url of urls) {
    const keepAllMexFile = /_MX/i.test(url);
    await parseOneEpg(url, agg, keepAllMexFile);
  }
  const kept = new Set([...agg.nameMap.values()]);
  console.log(`EPG entries kept (Mexico-related): ${kept.size}`);
  return { nameMap: agg.nameMap, entries: [...kept] };
}

// ---------- MATCH ----------
function jaccard(aTokens, bTokens) {
  const A = new Set(aTokens), B = new Set(bTokens);
  let inter = 0; for (const t of A) if (B.has(t)) inter++;
  return inter / (A.size + B.size - inter || 1);
}
function findMatchByName(channelName, nameKey, nameMap, entries) {
  const exact = nameMap.get(nameKey);
  if (exact) return { entry: exact, score: 1, method: 'exact' };
  const sTokArr = tokensOf(channelName);
  const sTok = new Set(sTokArr);

  // anchor
  if (sTok.size === 1) {
    const [only] = [...sTok];
    for (const e of entries) if (e.tokenSet && e.tokenSet.has(only)) {
      return { entry: e, score: 0.99, method: 'anchor' };
    }
  }
  // subset
  let subsetBest = null, subsetBestSize = Infinity;
  for (const e of entries) {
    const E = e.tokenSet || new Set();
    let allIn = true;
    for (const t of sTok) { if (!E.has(t)) { allIn = false; break; } }
    if (allIn && E.size < subsetBestSize) { subsetBest = e; subsetBestSize = E.size; }
  }
  if (subsetBest) return { entry: subsetBest, score: 0.9, method: 'subset' };

  // fuzzy
  let best = null, bestScore = 0;
  for (const e of entries) for (const nm of e.names) {
    const score = jaccard(sTokArr, tokensOf(nm));
    if (score > bestScore) { bestScore = score; best = e; }
  }
  if (best && bestScore >= FUZZY_MIN) return { entry: best, score: bestScore, method: 'fuzzy' };
  return { entry: null, score: 0, method: 'none' };
}

// ---------- DB ----------
function supabaseClient() {
  return createClient(SUPABASE_URL, SUPABASE_SERVICE_KEY, {
    auth: { persistSession: false },
    db: { schema: SUPABASE_SCHEMA }
  });
}

async function saveStreams(rows) {
  if (!SUPABASE_URL || !SUPABASE_SERVICE_KEY) {
    console.log('Supabase env missing; skipped DB upload.');
    return;
  }
  if (!rows.length) {
    console.log('No stream rows to upload to Supabase.');
    return;
  }
  const sb = supabaseClient();

  // Try with tvg_id included first; if it fails due to missing column, retry without it.
  const tryUpsert = async (withTvgId) => {
    const payload = rows.map(r => {
      const base = {
        stream_url: r.stream_url,
        channel_guess: r.channel_guess,
        epg_channel_id: r.epg_channel_id,
        epg_display_name: r.epg_display_name,
        working: r.working,
        checked_at: r.checked_at
      };
      if (withTvgId && r.tvg_id != null) base.tvg_id = r.tvg_id;
      return base;
    });
    return await sb.from(SUPABASE_TABLE).upsert(payload, { onConflict: 'stream_url', ignoreDuplicates: false });
  };

  let { error } = await tryUpsert(true);
  if (error && /tvg_id/i.test(error.message || '')) {
    console.warn(`Upsert retry without tvg_id due to: ${error.message}`);
    ({ error } = await tryUpsert(false));
  }
  if (error) {
    console.warn(`Streams upsert failed: ${error.message} (${error.code ?? 'no-code'})`);
  } else {
    console.log(`Streams DB write OK: ${rows.length} rows`);
  }
}

async function saveProgramsBatch(batch) {
  if (!INGEST_PROGRAMS || !batch.length) return;
  if (!SUPABASE_URL || !SUPABASE_SERVICE_KEY) {
    console.log('Supabase env missing; skipped programs upload.');
    return;
  }
  const sb = supabaseClient();
  const payload = batch.map(x => ({
    channel_id: x.channel_id,
    title: x.title,
    sub_title: x.sub_title,
    summary: x.summary,
    start_ts: x.start_ts,
    stop_ts: x.stop_ts,
    categories: x.categories,
    icon_url: x.icon_url,
    rating: x.rating,
    star_rating: x.star_rating,
    program_url: x.program_url,
    episode_num_xmltv: x.episode_num_xmltv,
    season: x.season,
    episode: x.episode,
    language: x.language,
    orig_language: x.orig_language,
    credits: x.credits,
    premiere: x.premiere,
    previously_shown: x.previously_shown,
    extras: x.extras,
    ingested_at: x.ingested_at
  }));
  const { error } = await sb.from(PROGRAMS_TABLE).insert(payload);
  if (error) console.warn(`Programs insert failed: ${error.message} (${error.code ?? 'no-code'})`);
}

// ---------- MAIN ----------
async function ensureDir(p) { await fs.mkdir(p, { recursive: true }); }

async function main() {
  if (!EPG_URLS.length) throw new Error('No EPG URLs provided in MX_EPG_URLS');

  await ensureDir('out/mx');
  const browser = await chromium.launch({ headless: HEADLESS });

  const m3u = await buildM3ULookups();

  try {
    console.log(`Scraping: ${SEARCH_URL}`);
    const links = await collectChannelPages(browser);
    console.log(`Found ${links.length} channel pages.`);

    const scraped = await scrapeAll(browser, links);
    console.log(`Channels with at least one .m3u8 (before probe): ${scraped.length}`);

    // probe streams
    for (const row of scraped) {
      const tested = [];
      for (const s of row.streams) {
        const ok = await probeM3U8(s.url);
        if (ok) tested.push(s);
      }
      row.streams = tested;
    }
    const filtered = scraped.filter(r => r.streams.length > 0);
    console.log(`Channels with at least one WORKING .m3u8: ${filtered.length}`);

    const { nameMap, entries } = await parseAllEpg(EPG_URLS);

    const records = [];
    const matchedOnly = [];
    for (const r of filtered) {
      // First try M3U tvg-id (by exact URL, else by normalized name)
      const nameTvg = m3u.byNameNorm.get(r.channelNameKey) || null;

      const { entry, method } = findMatchByName(r.channelName, r.channelNameKey, nameMap, entries);
      for (const s of r.streams) {
        const urlTvg = m3u.byUrl.get(s.url) || null;
        const tvg_id = urlTvg || nameTvg || (entry ? entry.id : null);

        const rec = {
          stream_url: s.url,
          channel_guess: r.channelName,
          tvg_id,
          epg_channel_id: entry ? entry.id : tvg_id,
          epg_display_name: entry ? (entry.names[0] || null) : null,
          working: true,
          checked_at: new Date().toISOString()
        };
        records.push(rec);
        if (entry) matchedOnly.push({ ...rec, _match_method: method });
      }
    }

    console.log(`Matched with EPG: ${matchedOnly.length} stream rows (across ${filtered.length} channels).`);

    await fs.writeFile(path.join('out', 'mx', 'records.json'), JSON.stringify(records, null, 2), 'utf8');
    await fs.writeFile(path.join('out', 'mx', 'matches.json'), JSON.stringify(matchedOnly, null, 2), 'utf8');

    if (LOG_UNMATCHED) {
      const matchedUrls = new Set(matchedOnly.map(x => x.stream_url));
      const unmatched = records.filter(x => !matchedUrls.has(x.stream_url));
      await fs.writeFile(path.join('out', 'mx', 'unmatched.json'), JSON.stringify(unmatched, null, 2), 'utf8');
      console.log(`Wrote out/mx/unmatched.json with ${unmatched.length} unmatched rows`);
    }

    await saveStreams(records);

    // Optional programme sample artifact (useful for quick sanity)
    if (INGEST_PROGRAMS) {
      await fs.writeFile(path.join('out','mx','epg_programs_sample.json'),
        JSON.stringify({ note: 'programs inserted directly to DB in batches; this is just a stub artifact' }, null, 2),
        'utf8'
      );
    }
  } finally {
    await browser.close();
  }
}

main().catch((e) => { console.error(e); process.exit(1); });
EOF

      - name: Run MX scrape & match
        run: node scripts/mx-scrape-and-match.mjs

      - name: NordVPN disconnect
        if: always()
        run: |
          set -euo pipefail
          if command -v nordvpn >/dev/null 2>&1; then
            sudo nordvpn disconnect || true
            sudo nordvpn status || true
          fi

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: mx-output
          path: |
            out/mx/records.json
            out/mx/matches.json
            out/mx/unmatched.json
            out/mx/epg_programs_sample.json
          if-no-files-found: warn

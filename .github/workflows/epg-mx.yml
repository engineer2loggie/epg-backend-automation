name: EPG-MX
on:
  workflow_dispatch:
  schedule:
    - cron: "0 7 * * *"

jobs:
  mx:
    runs-on: ubuntu-latest
    timeout-minutes: 300
    env:
      MX_SEARCH_URL: https://iptv-org.github.io/?q=live%20country:MX
      MX_EPG_URL: https://epgshare01.online/epgshare01/epg_ripper_MX1.xml.gz
      HEADLESS: "true"
      MAX_CHANNELS: "0"
      PER_PAGE_DELAY_MS: "150"
      NAV_TIMEOUT_MS: "30000"
      PROBE_TIMEOUT_MS: "5000"
      SUPABASE_TABLE: epg_streams
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Install dependencies
        run: |
          npm i --no-save playwright fast-xml-parser @supabase/supabase-js
          npx playwright install --with-deps chromium

      - name: Write scraper script to file
        shell: bash
        run: |
          mkdir -p scripts out/mx
          cat > scripts/mx-scrape-and-match.mjs <<'EOF'
# Scrape iptv-org.github.io for live MX channels, pull .m3u8s,
# download EPGShare MX XML, match by display-name, probe stream, write artifact,
# and optionally upsert to Supabase.

import { chromium } from 'playwright';
import { XMLParser } from 'fast-xml-parser';
import zlib from 'node:zlib';
import fs from 'node:fs/promises';
import path from 'node:path';
import { setTimeout as delay } from 'node:timers/promises';
import { createClient } from '@supabase/supabase-js';

// --- CONFIGURATION ---
const SEARCH_URL = process.env.MX_SEARCH_URL || 'https://iptv-org.github.io/?q=live%20country:MX';
const EPG_GZ_URL = process.env.MX_EPG_URL || 'https://epgshare01.online/epgshare01/epg_ripper_MX1.xml.gz';
const HEADLESS = (process.env.HEADLESS ?? 'true') !== 'false';
const MAX_CHANNELS = Number(process.env.MAX_CHANNELS || '0'); // 0 for no limit
const PER_PAGE_DELAY_MS = Number(process.env.PER_PAGE_DELAY_MS || '150');
const NAV_TIMEOUT_MS = Number(process.env.NAV_TIMEOUT_MS || '30000');
const PROBE_TIMEOUT_MS = Number(process.env.PROBE_TIMEOUT_MS || '5000');
const SUPABASE_URL = process.env.SUPABASE_URL || '';
const SUPABASE_SERVICE_KEY = process.env.SUPABASE_SERVICE_KEY || '';
const SUPABASE_TABLE = process.env.SUPABASE_TABLE || 'epg_streams';

// --- UTILITY FUNCTIONS ---
const STOP_WORDS = new Set(['canal', 'tv', 'television', 'hd', 'sd', 'mx', 'mexico', 'mÃ©xico']);

function normalizeString(s) {
  if (!s) return '';
  const plain = s.normalize('NFD').replace(/\p{Diacritic}+/gu, '').toLowerCase();
  const cleaned = plain.replace(/&/g, ' and ').replace(/[^a-z0-9]+/g, ' ').trim();
  return cleaned.split(/\s+/).filter(t => t && !STOP_WORDS.has(t)).sort().join(' ');
}

function uniqBy(arr, keyFn) {
  const seen = new Map();
  for (const item of arr) {
    const key = keyFn(item);
    if (!seen.has(key)) seen.set(key, item);
  }
  return [...seen.values()];
}

async function fetchBuffer(url) {
  const response = await fetch(url);
  if (!response.ok) throw new Error(`Fetch failed with status ${response.status} for ${url}`);
  return Buffer.from(await response.arrayBuffer());
}

// --- SCRAPING LOGIC ---
async function collectChannelPages(browser) {
  const page = await browser.newPage();
  page.setDefaultTimeout(NAV_TIMEOUT_MS);
  await page.goto(SEARCH_URL, { waitUntil: 'domcontentloaded' });
  await page.waitForSelector('a[href*="/channels/"]', { timeout: 15000 }).catch(() => {});
  await delay(1000);

  let items = await page.$$eval('a[href*="/channels/"]', anchors => {
    return anchors.map(a => {
      const row = a.closest('tr,li,article,div') || a.parentElement;
      const img = row ? row.querySelector('img') : null;
      return {
        url: new URL(a.getAttribute('href'), location.href).href,
        name: (a.textContent || '').trim(),
        logo: img ? (img.src || img.getAttribute('src')) : null
      };
    });
  });
  
  await page.close();
  
  items = uniqBy(items.filter(i => i.name && i.url.includes('/channels/')), i => i.url);
  const finalItems = MAX_CHANNELS > 0 ? items.slice(0, MAX_CHANNELS) : items;
  return finalItems.map(i => ({ ...i, nameKey: normalizeString(i.name) }));
}

async function scrapeChannelForStreams(browser, channel) {
  const page = await browser.newPage();
  page.setDefaultTimeout(NAV_TIMEOUT_MS);
  try {
    await page.goto(channel.url, { waitUntil: 'domcontentloaded' });
    const streamsTab = await page.$('text=Streams');
    if (streamsTab) {
      await streamsTab.click().catch(() => {});
      await delay(400);
    }

    let streamLinks = await page.$$eval('a[href*=".m3u8"]', els =>
      els.map(e => ({ url: e.href, text: (e.textContent || '').trim() }))
    );

    if (streamLinks.length === 0) {
      const html = await page.content();
      const urls = html.match(/https?:\/\/[^\s"'<>]+\.m3u8[^\s"'<>]*/gi) || [];
      streamLinks = [...new Set(urls)].map(u => ({ url: u, text: '' }));
    }

    return uniqBy(streamLinks.filter(a => a.url.startsWith('http')), a => a.url)
      .map(a => ({
        url: a.url,
        quality: (a.text.match(/\b(1080p|720p|480p|360p|HD|SD)\b/i) || [])[0] || null
      }));
  } catch (e) {
    console.error(`Error scraping ${channel.url}: ${e.message}`);
    return [];
  } finally {
    await page.close();
  }
}

// --- STREAM PROBING ---
async function probeM3U8(url) {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), PROBE_TIMEOUT_MS);
  try {
    const response = await fetch(url, {
      method: 'GET',
      headers: { 'User-Agent': 'Mozilla/5.0', 'Accept': 'application/vnd.apple.mpegurl,text/plain,*/*' },
      signal: controller.signal
    });
    if (!response.ok) return false;
    const text = await response.text();
    return text.includes('#EXTM3U');
  } catch {
    return false;
  } finally {
    clearTimeout(timeoutId);
  }
}

// --- EPG PROCESSING ---
async function parseEpg() {
  console.log(`Downloading EPG from ${EPG_GZ_URL}`);
  const gzBuffer = await fetchBuffer(EPG_GZ_URL);
  const xml = zlib.gunzipSync(gzBuffer).toString('utf8');

  const parser = new XMLParser({ ignoreAttributes: false, attributeNamePrefix: '', trimValues: true });
  const doc = parser.parse(xml);

  const channels = [].concat(doc?.tv?.channel || []);
  const programmes = [].concat(doc?.tv?.programme || []);
  
  const channelsWithProgs = new Set(programmes.map(p => p.channel));
  const nameMap = new Map();

  for (const ch of channels) {
    if (!ch.id || !channelsWithProgs.has(ch.id)) continue;

    const names = new Set([ch.id].concat(ch['display-name']).filter(Boolean));
    const iconSrc = Array.isArray(ch.icon) ? ch.icon[0]?.src : ch.icon?.src;
    const entry = { id: ch.id, names: [...names], icon: iconSrc || null };

    for (const name of names) {
      const key = normalizeString(name);
      if (key && !nameMap.has(key)) nameMap.set(key, entry);
    }
  }
  
  console.log(`EPG: Found ${channels.length} channels, ${nameMap.size} with active programmes.`);
  return { nameMap };
}

// --- DATA MATCHING & SAVING ---
function matchData(scrapedChannels, epgNameMap) {
  const matches = [];
  for (const channel of scrapedChannels) {
    const epgEntry = epgNameMap.get(channel.nameKey);
    if (epgEntry) {
      matches.push({
        channelName: channel.name,
        channelPage: channel.url,
        logo: channel.logo,
        streams: channel.streams,
        epgChannelId: epgEntry.id,
        epgDisplayNames: epgEntry.names,
        epgIcon: epgEntry.icon
      });
    }
  }
  return matches;
}

async function upsertToSupabase(rows) {
  if (!SUPABASE_URL || !SUPABASE_SERVICE_KEY || rows.length === 0) {
    console.log('Supabase upload skipped (missing config or no data).');
    return;
  }
  const supabase = createClient(SUPABASE_URL, SUPABASE_SERVICE_KEY, { auth: { persistSession: false } });
  const payload = rows.flatMap(r => 
    r.streams.map(s => ({
      country: 'MX',
      channel_name: r.channelName,
      channel_logo: r.logo,
      channel_page: r.channelPage,
      stream_url: s.url,
      stream_quality: s.quality,
      epg_channel_id: r.epgChannelId,
      epg_display_names: r.epgDisplayNames,
      epg_icon: r.epgIcon
    }))
  );

  const { error } = await supabase.from(SUPABASE_TABLE).upsert(payload, {
    onConflict: 'country,channel_name,stream_url',
    ignoreDuplicates: false
  });

  if (error) throw error;
  console.log(`Supabase upsert successful: ${payload.length} rows.`);
}

// --- MAIN EXECUTION ---
async function main() {
  await fs.mkdir('out/mx', { recursive: true });
  const browser = await chromium.launch({ headless: HEADLESS });
  try {
    console.log(`Starting scrape from: ${SEARCH_URL}`);
    const channelLinks = await collectChannelPages(browser);
    console.log(`Found ${channelLinks.length} unique channel pages.`);

    const scrapedChannels = [];
    for (const link of channelLinks) {
      const streams = await scrapeChannelForStreams(browser, link);
      if (streams.length > 0) {
        const workingStreams = [];
        for (const stream of streams) {
          if (await probeM3U8(stream.url)) {
            workingStreams.push(stream);
          }
        }
        if (workingStreams.length > 0) {
          scrapedChannels.push({ ...link, streams: workingStreams });
        }
      }
      await delay(PER_PAGE_DELAY_MS);
    }
    console.log(`Found ${scrapedChannels.length} channels with at least one working stream.`);

    const { nameMap } = await parseEpg();
    const matched = matchData(scrapedChannels, nameMap);
    console.log(`Successfully matched ${matched.length} channels with EPG data.`);

    const outPath = path.join('out', 'mx', 'matches.json');
    await fs.writeFile(outPath, JSON.stringify(matched, null, 2), 'utf8');
    console.log(`Wrote matches to ${outPath}`);

    await upsertToSupabase(matched);
  } finally {
    await browser.close();
  }
}

main().catch((e) => {
  console.error('An unexpected error occurred:', e);
  process.exit(1);
});
EOF

      - name: Run scraper script
        run: node scripts/mx-scrape-and-match.mjs

      - name: Upload results artifact
        uses: actions/upload-artifact@v4
        with:
          name: mx-matches
          path: out/mx/matches.json
          if-no-files-found: error

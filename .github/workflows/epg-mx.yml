name: EPG-MX

on:
  workflow_dispatch:
  schedule:
    - cron: "0 7 * * *" # daily 07:00 UTC

concurrency:
  group: epg-mx
  cancel-in-progress: true

jobs:
  mx:
    runs-on: ubuntu-latest
    timeout-minutes: 300
    env:
      MX_SEARCH_URL: https://iptv-org.github.io/?q=live%20country:MX
      MX_EPG_URL: https://epgshare01.online/epgshare01/epg_ripper_ALL_SOURCES1.xml.gz
      HEADLESS: "true"
      MAX_CHANNELS: "0"           # set to e.g. 25 for test runs
      PER_PAGE_DELAY_MS: "150"
      NAV_TIMEOUT_MS: "30000"
      PROBE_TIMEOUT_MS: "5000"
      FUZZY_MIN: "0.45"           # looser fuzzy match
      LOG_UNMATCHED: "1"          # write unmatched.json for debugging

      # Supabase (points at your mx_channels schema)
      SUPABASE_SCHEMA: public
      SUPABASE_TABLE: mx_channels
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}

    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Install Playwright and deps
        run: |
          npm i --no-save playwright fast-xml-parser @supabase/supabase-js
          npx playwright install --with-deps chromium

      - name: Write script
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p scripts out/mx
          cat > scripts/mx-scrape-and-match.mjs <<'EOF'
          import { chromium } from 'playwright';
          import { XMLParser } from 'fast-xml-parser';
          import zlib from 'node:zlib';
          import fs from 'node:fs/promises';
          import path from 'node:path';
          import { setTimeout as delay } from 'node:timers/promises';
          import { createClient } from '@supabase/supabase-js';

          const SEARCH_URL = process.env.MX_SEARCH_URL || 'https://iptv-org.github.io/?q=live%20country:MX';
          const EPG_GZ_URL = process.env.MX_EPG_URL || 'https://epgshare01.online/epgshare01/epg_ripper_ALL_SOURCES1.xml.gz';

          const HEADLESS = (process.env.HEADLESS ?? 'true') !== 'false';
          const MAX_CHANNELS = Number(process.env.MAX_CHANNELS || '0');
          const PER_PAGE_DELAY_MS = Number(process.env.PER_PAGE_DELAY_MS || '150');
          const NAV_TIMEOUT_MS = Number(process.env.NAV_TIMEOUT_MS || '30000');
          const PROBE_TIMEOUT_MS = Number(process.env.PROBE_TIMEOUT_MS || '5000');
          const FUZZY_MIN = Number(process.env.FUZZY_MIN || '0.45');
          const LOG_UNMATCHED = process.env.LOG_UNMATCHED === '1';

          const SUPABASE_URL = process.env.SUPABASE_URL || '';
          const SUPABASE_SERVICE_KEY = process.env.SUPABASE_SERVICE_KEY || '';
          const SUPABASE_SCHEMA = process.env.SUPABASE_SCHEMA || 'public';
          const SUPABASE_TABLE = process.env.SUPABASE_TABLE || 'mx_channels';

          // ---------- helpers: normalization & tokenization ----------
          function stripAccents(s) { return String(s).normalize('NFD').replace(/\p{Diacritic}+/gu, ''); }
          function normalizeNumerals(s) {
            const map = { 'uno':'1','dos':'2','tres':'3','cuatro':'4','cinco':'5','seis':'6','siete':'7','ocho':'8','nueve':'9','diez':'10','once':'11','doce':'12','trece':'13' };
            return String(s).replace(/\b(uno|dos|tres|cuatro|cinco|seis|siete|ocho|nueve|diez|once|doce|trece)\b/gi, m => map[m.toLowerCase()]);
          }
          function dropTimeshift(s) {
            return String(s)
              .replace(/(?:[-+]\s*\d+\s*(?:h|hora|horas)\b)/ig,'')
              .replace(/\b\d+\s*horas?\b/ig,'')
              .replace(/\(\s*\d+\s*horas?\s*\)/ig,'')
              .replace(/\btime\s*shift\b/ig,'')
              .replace(/\s{2,}/g,' ')
              .trim();
          }
          function stripLeadingCanal(s) { return String(s).replace(/^\s*canal[\s._-]+/i, ''); }
          function stripCountryTagMx(s) { return String(s).replace(/(\.mx|\s+\(?mx\)?|\s+m[eé]xico)\s*$/i,'').trim(); }

          const STOP = new Set(['canal','tv','television','hd','sd','mx','mexico','méxico','hora','horas']);
          function tokensOf(s) {
            if (!s) return [];
            let plain = stripAccents(normalizeNumerals(String(s).toLowerCase()));
            plain = dropTimeshift(plain);
            plain = stripCountryTagMx(plain);
            plain = plain.replace(/&/g, ' and ').replace(/[^a-z0-9]+/g, ' ').trim();
            return plain.split(/\s+/).filter(t => t && !STOP.has(t));
          }
          function keyOf(s) { return Array.from(new Set(tokensOf(s))).sort().join(' '); }

          function expandNameVariants(s) {
            if (!s) return [];
            const out = new Set();
            const orig = String(s).trim();
            const noCanal = stripLeadingCanal(orig);
            const flat = x => x.replace(/[._]+/g, ' ').replace(/\s+/g, ' ').trim();
            const noTS = dropTimeshift(noCanal);
            const noMx = stripCountryTagMx(noTS);
            [orig, noCanal, noTS, noMx, flat(orig), flat(noCanal), flat(noTS), flat(noMx)]
              .forEach(v => { if (v) out.add(v); });
            return [...out];
          }

          function uniqBy(arr, keyFn) {
            const m = new Map();
            for (const x of arr) {
              const k = keyFn(x);
              if (!m.has(k)) m.set(k, x);
            }
            return [...m.values()];
          }

          async function fetchBuf(url) {
            const r = await fetch(url);
            if (!r.ok) throw new Error(`Fetch failed ${r.status} ${url}`);
            return Buffer.from(await r.arrayBuffer());
          }

          // ---------- SCRAPE CHANNEL LIST PAGE ----------
          async function collectChannelPages(browser) {
            const page = await browser.newPage();
            page.setDefaultTimeout(NAV_TIMEOUT_MS);
            await page.goto(SEARCH_URL, { waitUntil: 'domcontentloaded' });
            await page.waitForSelector('a[href*="/channels/"]', { timeout: 15000 }).catch(() => {});
            await page.waitForTimeout(1000);

            let items = await page.$$eval('a[href*="/channels/"]', (as) => {
              const out = [];
              for (const a of as) {
                const href = a.getAttribute('href') || '';
                if (!href.includes('/channels/')) continue;
                const url = new URL(href, location.href).href;
                const name = (a.textContent || '').trim();
                let logo = null;
                const row = a.closest('tr,li,article,div') || a.parentElement;
                if (row) {
                  const img = row.querySelector('img');
                  if (img) logo = img.src || img.getAttribute('src');
                }
                out.push({ url, name, logo });
              }
              const m = new Map();
              for (const it of out) if (!m.has(it.url)) m.set(it.url, it);
              return [...m.values()];
            });

            items = items.filter(i => i.name && i.url);
            items = uniqBy(items, x => x.url);

            if (MAX_CHANNELS > 0 && items.length > MAX_CHANNELS) items = items.slice(0, MAX_CHANNELS);
            await page.close();
            return items.map(i => ({ ...i, nameKey: keyOf(i.name) }));
          }

          // ---------- SCRAPE PER-CHANNEL PAGE FOR .m3u8 ----------
          async function scrapeChannel(browser, link) {
            const page = await browser.newPage();
            page.setDefaultTimeout(NAV_TIMEOUT_MS);
            try {
              await page.goto(link.url, { waitUntil: 'domcontentloaded' });
              await page.waitForTimeout(500);
              const tab = await page.$('text=Streams');
              if (tab) { await tab.click().catch(() => {}); await page.waitForTimeout(400); }

              let anchors = await page.$$eval('a[href*=".m3u8"]', els =>
                els.map(e => ({ url: e.href, text: (e.textContent || '').trim() }))
              );

              if (!anchors.length) {
                const html = await page.content();
                const rx = /https?:\/\/[^\s"'<>]+\.m3u8[^\s"'<>]*/gi;
                const set = new Set();
                let m; while ((m = rx.exec(html))) set.add(m[0]);
                anchors = [...set].map(u => ({ url: u, text: '' }));
              }

              anchors = uniqBy(anchors.filter(a => /^https?:\/\//i.test(a.url)), a => a.url);

              return anchors.map(a => ({
                url: a.url,
                quality: (a.text.match(/\b(1080p|720p|480p|360p|HD|SD)\b/i) || [])[0] || null
              }));
            } catch (e) {
              console.error(`Error scraping ${link.url}: ${e.message}`);
              return [];
            } finally {
              await page.close();
            }
          }

          async function scrapeAll(browser, links) {
            const out = [];
            for (const lnk of links) {
              const streams = await scrapeChannel(browser, lnk);
              if (streams.length) {
                out.push({
                  channelName: lnk.name,
                  channelNameKey: lnk.nameKey,
                  channelPage: lnk.url,
                  logo: lnk.logo || null,
                  streams
                });
              }
              await delay(PER_PAGE_DELAY_MS);
            }
            return out;
          }

          // ---------- PROBE M3U8 QUICKLY ----------
          async function probeM3U8(url) {
            const ac = new AbortController();
            const t = setTimeout(() => ac.abort(), PROBE_TIMEOUT_MS);
            try {
              const r = await fetch(url, {
                method: 'GET',
                headers: { 'user-agent': 'Mozilla/5.0', 'accept': 'application/vnd.apple.mpegurl,text/plain,*/*' },
                signal: ac.signal
              });
              if (!r.ok) return false;
              const txt = await r.text();
              return txt.includes('#EXTM3U');
            } catch { return false; }
            finally { clearTimeout(t); }
          }

          // ---------- PARSE EPG (ALL SOURCES) & BUILD INDEX (Mexico only-ish) ----------
          function isMexicoEntry(id, names) {
            return /\.mx$/i.test(id) || names.some(n => /\b(m[eé]xico|mx)\b/i.test(String(n)));
          }

          async function parseEpg() {
            console.log(`Downloading EPG… ${EPG_GZ_URL}`);
            const gz = await fetchBuf(EPG_GZ_URL);
            const xmlBuf = zlib.gunzipSync(gz);
            const xml = xmlBuf.toString('utf8');

            const parser = new XMLParser({ ignoreAttributes: false, attributeNamePrefix: '', trimValues: true });
            const doc = parser.parse(xml);

            const channels = doc?.tv?.channel ? (Array.isArray(doc.tv.channel) ? doc.tv.channel : [doc.tv.channel]) : [];
            const programmes = doc?.tv?.programme ? (Array.isArray(doc.tv.programme) ? doc.tv.programme : [doc.tv.programme]) : [];

            const idTo = new Map();
            const nameMap = new Map();

            for (const ch of channels) {
              const id = ch?.id;
              if (!id) continue;

              // names
              const namesRaw = [];
              const dn = ch['display-name'];
              const add = v => { if (!v) return; if (typeof v === 'string') namesRaw.push(v); else if (typeof v === 'object') namesRaw.push(v['#text'] || v.text || ''); };
              if (Array.isArray(dn)) dn.forEach(add); else add(dn);

              if (!isMexicoEntry(id, namesRaw)) continue;

              const names = [];
              for (const n of namesRaw) for (const v of expandNameVariants(n)) names.push(v);
              for (const v of expandNameVariants(id)) names.push(v);

              const entry = { id, names: Array.from(new Set(names.filter(Boolean))), hasProgs: false };
              idTo.set(id, entry);
              for (const n of entry.names) {
                const k = keyOf(n);
                if (!k) continue;
                if (!nameMap.has(k)) nameMap.set(k, entry);
              }
            }

            for (const p of programmes) {
              const cid = p?.channel;
              const o = idTo.get(cid);
              if (o) o.hasProgs = true;
            }

            for (const [k, v] of nameMap.entries()) if (!v.hasProgs) nameMap.delete(k);

            console.log(`EPG entries kept (Mexico-ish): ${new Set([...nameMap.values()]).size}`);
            return { nameMap, entries: [...new Set([...nameMap.values()])] };
          }

          // ---------- MATCH ----------
          function jaccard(aTokens, bTokens) {
            const A = new Set(aTokens), B = new Set(bTokens);
            let inter = 0; for (const t of A) if (B.has(t)) inter++;
            return inter / (A.size + B.size - inter || 1);
          }

          function findMatch(channelName, nameKey, nameMap, entries) {
            const exact = nameMap.get(nameKey);
            if (exact) return { entry: exact, score: 1, method: 'exact' };

            const sTokens = tokensOf(channelName);
            let best = null, bestScore = 0;
            for (const e of entries) {
              for (const nm of e.names) {
                const score = jaccard(sTokens, tokensOf(nm));
                if (score > bestScore) { bestScore = score; best = e; }
              }
            }
            if (best && bestScore >= FUZZY_MIN) return { entry: best, score: bestScore, method: 'fuzzy' };
            return { entry: null, score: 0, method: 'none' };
          }

          // ---------- SUPABASE UPSERT ----------
          async function upsertRows(rows) {
            if (!SUPABASE_URL || !SUPABASE_SERVICE_KEY) {
              console.log('Supabase env missing; skipped DB upload.');
              return;
            }
            if (!rows.length) {
              console.log('No rows to upload to Supabase.');
              return;
            }
            const supabase = createClient(SUPABASE_URL, SUPABASE_SERVICE_KEY, {
              auth: { persistSession: false },
              db: { schema: SUPABASE_SCHEMA }
            });

            // NOTE: upsert requires a unique index/PK; ideally unique on (stream_url)
            const { error } = await supabase.from(SUPABASE_TABLE).upsert(rows, {
              onConflict: 'stream_url',
              ignoreDuplicates: false
            });
            if (error) {
              console.warn(`Supabase upsert warning: ${error.message} (${error.code ?? 'no-code'})`);
            } else {
              console.log(`Supabase upsert done: ${rows.length} rows`);
            }
          }

          // ---------- MAIN ----------
          async function ensureDir(p) { await fs.mkdir(p, { recursive: true }); }

          async function main() {
            await ensureDir('out/mx');
            const browser = await chromium.launch({ headless: HEADLESS });
            try {
              console.log(`Scraping: ${SEARCH_URL}`);
              const links = await collectChannelPages(browser);
              console.log(`Found ${links.length} channel pages.`);
              const scraped = await scrapeAll(browser, links);
              console.log(`Channels with at least one .m3u8 (before probe): ${scraped.length}`);

              for (const row of scraped) {
                const tested = [];
                for (const s of row.streams) {
                  const ok = await probeM3U8(s.url);
                  if (ok) tested.push(s);
                }
                row.streams = tested;
              }
              const filtered = scraped.filter(r => r.streams.length > 0);
              console.log(`Channels with at least one WORKING .m3u8: ${filtered.length}`);

              const { nameMap, entries } = await parseEpg();

              // Build records for DB (include unmatched)
              const records = [];
              const matchedOnly = [];
              for (const r of filtered) {
                const { entry } = findMatch(r.channelName, r.channelNameKey, nameMap, entries);
                for (const s of r.streams) {
                  const rec = {
                    stream_url: s.url,
                    channel_guess: r.channelName,
                    epg_channel_id: entry ? entry.id : null,
                    epg_display_name: entry ? (entry.names[0] || null) : null,
                    working: true,
                    checked_at: new Date().toISOString()
                  };
                  records.push(rec);
                  if (entry) matchedOnly.push(rec);
                }
              }

              console.log(`Matched with EPG: ${matchedOnly.length} stream rows (across ${filtered.length} channels).`);

              await fs.writeFile(path.join('out', 'mx', 'records.json'), JSON.stringify(records, null, 2), 'utf8');
              await fs.writeFile(path.join('out', 'mx', 'matches.json'), JSON.stringify(matchedOnly, null, 2), 'utf8');

              if (LOG_UNMATCHED) {
                const matchedUrls = new Set(matchedOnly.map(x => x.stream_url));
                const unmatched = records.filter(x => !matchedUrls.has(x.stream_url));
                await fs.writeFile(path.join('out', 'mx', 'unmatched.json'), JSON.stringify(unmatched, null, 2), 'utf8');
                console.log(`Wrote out/mx/unmatched.json with ${unmatched.length} unmatched rows`);
              }

              await upsertRows(records);
            } finally {
              await browser.close();
            }
          }

          main().catch((e) => { console.error(e); process.exit(1); });
          EOF

      - name: Run MX scrape & match
        run: node scripts/mx-scrape-and-match.mjs

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: mx-output
          path: |
            out/mx/records.json
            out/mx/matches.json
            out/mx/unmatched.json
          if-no-files-found: ignore

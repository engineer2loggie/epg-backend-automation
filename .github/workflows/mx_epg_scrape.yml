name: MX-EPG-SCRAPE

on:
  workflow_dispatch: {}
  schedule:
    - cron: "3 */6 * * *"  # every 6 hours at :03

concurrency:
  group: mx-epg-scrape
  cancel-in-progress: false

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: "Install dependencies (Option A: explicit Playwright)"
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install playwright
          python -m playwright install --with-deps chromium

      - name: Run scraper
        env:
          PYTHONUNBUFFERED: "1"
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          set -euo pipefail
          mkdir -p logs
          # Run as a module so 'scripts' behaves like a package
          python -m scripts.scrape_mx_epg 2>&1 | tee "logs/scrape_${{ github.run_id }}.log"

      - name: Upload logs (always)
        if: ${{ always() }}
        uses: actions/upload-artifact@v4
        with:
          name: mx-epg-scrape-logs
          path: logs/*.log
